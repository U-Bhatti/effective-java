<div>
    <h1>Item 48: Use caution when making streams parallel</h1>

    <p>Among mainstream languages, Java has always been at the forefront of providing facilities to ease the
        task of
        concurrent programming. When Java was released in 1996, it had built-in support for threads, with
        synchronization and wait/notify. Java 5 introduced the <code>java.util.concurrent</code> library, with
        concurrent collections and the executor framework. Java 7 introduced the fork-join package, a
        high-performance framework for parallel decomposition. Java 8 introduced streams, which can be
        parallelized
        with a single call to the <code>parallel</code> method. Writing concurrent programs in Java keeps
        getting
        easier, but writing concurrent programs that are correct and fast is as difficult as it ever was. Safety
        and
        liveness violations are a fact of life in concurrent programming, and parallel stream pipelines are no
        exception.</p>

    <p>Consider this program from <strong>Item 45</strong>:</p>
    <pre><code class="language-java hljs">    <span class="hljs-comment">// Stream-based program to generate the first 20 Mersenne primes</span>
<span class="hljs-keyword">public</span> <span class="hljs-keyword">static</span> <span class="hljs-keyword">void</span> <span class="hljs-title function_">main</span><span class="hljs-params">(String[] args)</span> {
    primes().map(p -&gt; TWO.pow(p.intValueExact()).subtract(ONE))
        .filter(mersenne -&gt; mersenne.isProbablePrime(<span class="hljs-number">50</span>))
        .limit(<span class="hljs-number">20</span>)
        .forEach(System.out::println);
}</code><code class="language-java hljs">    <span class="hljs-keyword">static</span> Stream&lt;BigInteger&gt; <span class="hljs-title function_">primes</span><span class="hljs-params">()</span> {
    <span class="hljs-keyword">return</span> Stream.iterate(TWO, BigInteger::nextProbablePrime);
}</code></pre>

    <p>On my machine, this program immediately starts printing primes and takes 12.5 seconds to run to
        completion.
        Suppose I naively try to speed it up by adding a call to <code>parallel()</code> to the stream pipeline.
        What do you think will happen to its performance? Will it get a few percent faster? A few percent
        slower?
        Sadly, what happens is that it doesn’t print anything, but CPU usage spikes to 90 percent and stays
        there
        indefinitely (a liveness failure). The program might terminate eventually, but I was unwilling to find
        out;
        I stopped it forcibly after half an hour.</p>

    <p>What’s going on here? Simply put, the streams library has no idea how to parallelize this pipeline and
        the
        heuristics fail. Even under the best of circumstances, parallelizing a pipeline is unlikely to increase
        its
        performance if the source is from <code>Stream.iterate</code>, or the intermediate operation
        <code>limit</code> is used. This pipeline has to contend with both of these issues. Worse, the default
        parallelization strategy deals with the unpredictability of <code>limit</code> by assuming there’s no
        harm
        in processing a few extra elements and discarding any unneeded results. In this case, it takes roughly
        twice
        as long to find each Mersenne prime as it did to find the previous one. Thus, the cost of computing a
        single
        extra element is roughly equal to the cost of computing all previous elements combined, and this
        innocuous-looking pipeline brings the automatic parallelization algorithm to its knees. The moral of
        this
        story is simple: Do not parallelize stream pipelines indiscriminately. The performance consequences may
        be
        disastrous.
    </p>

    <p>As a rule, performance gains from parallelism are best on streams over <code>ArrayList</code>,
        <code>HashMap</code>, <code>HashSet</code>, and <code>ConcurrentHashMap</code> instances; arrays;
        <code>int</code> ranges; and <code>long</code> ranges. What these data structures have in common is that
        they can all be accurately and cheaply split into subranges of any desired sizes, which makes it easy to
        divide work among parallel threads. The abstraction used by the streams library to perform this task is
        the
        <code>Spliterator</code>, which is returned by the <code>spliterator</code> method on
        <code>Stream</code>
        and <code>Iterable</code>.
    </p>

    <p>Another important factor that all of these data structures have in common is that they provide
        good-to-excellent locality of reference when processed sequentially: sequential element references are
        stored together in memory. The objects referred to by those references may not be close to one another
        in
        memory, which reduces locality-of-reference. Locality-of-reference turns out to be critically important
        for
        parallelizing bulk operations: without it, threads spend much of their time idle, waiting for data to be
        transferred from memory into the processor’s cache. The data structures with the best locality of
        reference
        are primitive arrays because the data itself is stored contiguously in memory.</p>

    <p>The nature of a stream pipeline’s terminal operation also affects the effectiveness of parallel
        execution. If
        a significant amount of work is done in the terminal operation compared to the overall work of the
        pipeline
        and that operation is inherently sequential, then parallelizing the pipeline will have limited
        effectiveness. The best terminal operations for parallelism are reductions, where all of the elements
        emerging from the pipeline are combined using one of Stream’s <code>reduce</code> methods, or
        prepackaged
        reductions such as <code>min</code>, <code>max</code>, <code>count</code>, and <code>sum</code>. The
        short-circuiting operations <code>anyMatch</code>, <code>allMatch</code>, and <code>noneMatch</code> are
        also amenable to parallelism. The operations performed by Stream’s <code>collect</code> method, which
        are
        known as mutable reductions, are not good candidates for parallelism because the overhead of combining
        collections is costly.</p>

    <p>If you write your own Stream, Iterable, or Collection implementation and you want decent parallel
        performance, you must override the <code>spliterator</code> method and test the parallel performance of
        the
        resulting streams extensively. Writing high-quality spliterators is difficult and beyond the scope of
        this
        book.</p>

    <p>Not only can parallelizing a stream lead to poor performance, including liveness failures; it can lead to
        incorrect results and unpredictable behavior (safety failures). Safety failures may result from
        parallelizing a pipeline that uses mappers, filters, and other programmer-supplied function objects that
        fail to adhere to their specifications. The Stream specification places stringent requirements on these
        function objects. For example, the accumulator and combiner functions passed to Stream’s
        <code>reduce</code>
        operation must be associative, non-interfering, and stateless. If you violate these requirements (some
        of
        which are discussed in <strong>Item 46</strong>) but run your pipeline sequentially, it will likely
        yield
        correct results; if you parallelize it, it will likely fail, perhaps catastrophically.
    </p>

    <p>Along these lines, it’s worth noting that even if the parallelized Mersenne primes program had run to
        completion, it would not have printed the primes in the correct (ascending) order. To preserve the order
        displayed by the sequential version, you’d have to replace the <code>forEach</code> terminal operation
        with
        <code>forEachOrdered</code>, which is guaranteed to traverse parallel streams in encounter order.
    </p>

    <p>Even assuming that you’re using an efficiently splittable source stream, a parallelizable or cheap
        terminal
        operation, and non-interfering function objects, you won’t get a good speedup from parallelization
        unless
        the pipeline is doing enough real work to offset the costs associated with parallelism. As a very rough
        estimate, the number of elements in the stream times the number of lines of code executed per element
        should
        be at least a hundred thousand [Lea14].</p>

    <p>It’s important to remember that parallelizing a stream is strictly a performance optimization. As is the
        case
        for any optimization, you must test the performance before and after the change to ensure that it is
        worth
        doing (<strong>Item 67</strong>). Ideally, you should perform the test in a realistic system setting.
        Normally, all parallel stream pipelines in a program run in a common fork-join pool. A single
        misbehaving
        pipeline can harm the performance of others in unrelated parts of the system.</p>

    <p>If it sounds like the odds are stacked against you when parallelizing stream pipelines, it’s because they
        are. An acquaintance who maintains a multimillion-line codebase that makes heavy use of streams found
        only a
        handful of places where parallel streams were effective. This does not mean that you should refrain from
        parallelizing streams. Under the right circumstances, it is possible to achieve near-linear speedup in
        the
        number of processor cores simply by adding a <code>parallel</code> call to a stream pipeline. Certain
        domains, such as machine learning and data processing, are particularly amenable to these speedups.</p>

    <p>As a simple example of a stream pipeline where parallelism is effective, consider this function for
        computing
        <code>π(n)</code>, the number of primes less than or equal to <code>n</code>:
    </p>
    <pre><code class="language-java hljs">    <span class="hljs-comment">// Prime-counting stream pipeline - benefits from parallelization</span>
<span class="hljs-keyword">static</span> <span class="hljs-type">long</span> <span class="hljs-title function_">pi</span><span class="hljs-params">(<span class="hljs-type">long</span> n)</span> {
    <span class="hljs-keyword">return</span> LongStream.rangeClosed(<span class="hljs-number">2</span>, n)
        .mapToObj(BigInteger::valueOf)
        .filter(i -&gt; i.isProbablePrime(<span class="hljs-number">50</span>))
        .count();
}</code></pre>

    <p>On my machine, it takes 31 seconds to compute <code>π(10<sup>8</sup>)</code> using this function. Simply
        adding a <code>parallel()</code> call reduces the time to 9.2 seconds:</p>
    <pre><code class="language-java hljs">    <span class="hljs-comment">// Prime-counting stream pipeline - parallel version</span>
<span class="hljs-keyword">static</span> <span class="hljs-type">long</span> <span class="hljs-title function_">pi</span><span class="hljs-params">(<span class="hljs-type">long</span> n)</span> {
    <span class="hljs-keyword">return</span> LongStream.rangeClosed(<span class="hljs-number">2</span>, n)
        .parallel()
        .mapToObj(BigInteger::valueOf)
        .filter(i -&gt; i.isProbablePrime(<span class="hljs-number">50</span>))
        .count();
}</code></pre>

    <p>In other words, parallelizing the computation speeds it up by a factor of 3.7 on my quad-core machine.
        It’s
        worth noting that this is not how you’d compute <code>π(n)</code> for large values of <code>n</code> in
        practice. There are far more efficient algorithms, notably Lehmer’s formula.</p>

    <p>If you are going to parallelize a stream of random numbers, start with a <code>SplittableRandom</code>
        instance rather than a <code>ThreadLocalRandom</code> (or the essentially obsolete <code>Random</code>).
        <code>SplittableRandom</code> is designed for precisely this use, and has the potential for linear
        speedup.
        <code>ThreadLocalRandom</code> is designed for use by a single thread, and will adapt itself to function
        as
        a parallel stream source, but won’t be as fast as <code>SplittableRandom</code>. <code>Random</code>
        synchronizes on every operation, so it will result in excessive, parallelism-killing contention.
    </p>

    <p>In summary, do not even attempt to parallelize a stream pipeline unless you have good reason to believe
        that
        it will preserve the correctness of the computation and increase its speed. The cost of inappropriately
        parallelizing a stream can be a program failure or performance disaster. If you believe that parallelism
        may
        be justified, ensure that your code remains correct when run in parallel, and do careful performance
        measurements under realistic conditions. If your code remains correct and these experiments bear out
        your
        suspicion of increased performance, then and only then parallelize the stream in production code.</p>
</div>